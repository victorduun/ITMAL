{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ITMAL Exercise\n",
    "\n",
    "REVISIONS||\n",
    "---------||\n",
    "2018-1219| CEF, initial.                  \n",
    "2018-0206| CEF, updated and spell checked. \n",
    "2018-0208| CEF, minor text update.\n",
    "2018-0305| CEF, updated with SHN comments.\n",
    "2019-0902| CEF, updated for ITMAL v2.\n",
    "2019-0904| CEF, updated and added conclusion Q.\n",
    "2020-0125| CEF, F20 ITMAL update.\n",
    "2020-0204| CEF, updated page numbers to HOMLv2.\n",
    "\n",
    "## Implementing a dummy classifier with fit-predict interface\n",
    "\n",
    "We begin with the MNIST data-set and will reuse the data loader from Scikit-learn. Next we create a dummy classifier, and compare the results of the SGD and dummy classifiers using the MNIST data...\n",
    "\n",
    "#### Qa  Load and display the MNIST data\n",
    "\n",
    "There is a `sklearn.datasets.fetch_openml` dataloader interface in Scikit-learn. You can load MNIST data like \n",
    "\n",
    "```python\n",
    "from sklearn.datasets import fetch_openml\n",
    "# Load data from https://www.openml.org/d/554\n",
    "X, y = fetch_openml('mnist_784',??) # needs to return X, y, replace '??' with suitable parameters! \n",
    "# Convert at scale (not always needed)\n",
    "#X = X / 255.\n",
    "```\n",
    "\n",
    "but you need to set parameters like `return_X_y` and `cache` if the default values are not suitable! \n",
    "\n",
    "Check out the documentation for the `fetch_openml` MNIST loader, try it out by loading a (X,y) MNIST data set, and plot a single digit via the `MNIST_PlotDigit` function here (input data is a 28x28 NMIST subimage)\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "```\n",
    "\n",
    "Finally, put the MNIST loader into a single function called `MNIST_GetDataSet()` so you can resuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def MNIST_PlotDigit(data):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "\n",
    "def MNIST_GetDataSet():\n",
    "    # Load data from https://www.openml.org/d/554\n",
    "    X, y = fetch_openml('mnist_784', return_X_y=True)  \n",
    "    return X, y\n",
    "\n",
    "X, y =MNIST_GetDataSet()\n",
    "\n",
    "MNIST_PlotDigit(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qb  Add a Stochastic Gradient Decent [SGD] Classifier\n",
    "\n",
    "Create a train-test data-set for MNIST and then add the `SGDClassifier` as done in [HOML], p.88.\n",
    "\n",
    "Split your data and run the fit-predict for the classifier using the MNIST data.(We will be looking at cross-validation instead of the simple fit-predict in a later exercise.)\n",
    "\n",
    "Notice that you have to reshape the MNIST X-data to be able to use the classifier. It may be a 3D array, consisting of 70000 (28 x 28) images, or just a 2D array consisting of 70000 elements of size 784.\n",
    "\n",
    "A simple `reshape()` could fix this on-the-fly:\n",
    "```python\n",
    "X, y = MNIST_GetDataSet()\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "```\n",
    "\n",
    "Remember to use the category-5 y inputs\n",
    "\n",
    "```python\n",
    "y_train_5 = (y_train == '5')    \n",
    "y_test_5  = (y_test == '5')\n",
    "```\n",
    "instead of the `y`'s you are getting out of the dataloader...\n",
    "\n",
    "Test your model on using the test data, and try to plot numbers that have been categorized correctly. Then also find and plots some misclassified numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=(70000, 784)\n",
      "X.shape=(70000, 784)\n",
      "X_train.shape=(56000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": "SGDClassifier(random_state=42)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "#X, y = MNIST_GetDataSet()\n",
    "\n",
    "\n",
    "print(f\"X.shape={X.shape}\") # print X.shape= (70000, 28, 28)\n",
    "if X.ndim==3:\n",
    "    print(\"reshaping X..\")\n",
    "    assert y.ndim==1\n",
    "    X = X.reshape((X.shape[0],X.shape[1]*X.shape[2]))\n",
    "assert X.ndim==2\n",
    "print(f\"X.shape={X.shape}\") # X.shape= (70000, 784)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "print(f\"X_train.shape={X_train.shape}\")\n",
    "y_train_5 = (y_train == '5')  \n",
    "y_test_5 = (y_test == '5')  \n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2    21    57 ... 13977 13986 13990]\n",
      "[    2    21    57    78   109   119   169   192   265   285   315   339\n",
      "   375   477   488   513   520   563   577   579   602   626   628   760\n",
      "   836   967  1058  1063  1070  1088  1109  1118  1168  1278  1282  1302\n",
      "  1330  1345  1359  1406  1427  1492  1503  1516  1533  1534  1537  1558\n",
      "  1584  1645  1657  1694  1753  1779  1901  1918  1985  2061  2086  2094\n",
      "  2105  2112  2140  2146  2155  2163  2198  2206  2244  2281  2283  2295\n",
      "  2306  2349  2389  2440  2443  2487  2572  2640  2646  2665  2707  2733\n",
      "  2747  2763  2784  2806  2812  2853  2903  2963  3011  3058  3064  3104\n",
      "  3132  3140  3264  3284  3302  3423  3430  3448  3572  3637  3723  3769\n",
      "  3793  3816  3844  3884  4048  4076  4144  4180  4195  4228  4241  4302\n",
      "  4313  4345  4367  4373  4467  4535  4578  4613  4634  4680  4708  4742\n",
      "  4764  4804  4809  4819  4855  4874  5024  5073  5074  5096  5106  5113\n",
      "  5142  5224  5305  5335  5379  5402  5449  5461  5496  5524  5549  5563\n",
      "  5639  5661  5714  5758  5765  5847  5886  5915  5936  5960  5964  5975\n",
      "  6003  6004  6031  6033  6059  6078  6102  6152  6171  6191  6216  6306\n",
      "  6334  6361  6391  6401  6472  6532  6569  6570  6579  6637  6741  6788\n",
      "  6841  6864  6878  7033  7099  7132  7216  7244  7283  7329  7336  7361\n",
      "  7374  7377  7419  7461  7590  7616  7653  7675  7683  7707  7720  7728\n",
      "  7749  7786  7816  7821  7823  7846  7855  7857  7881  8024  8092  8105\n",
      "  8114  8139  8231  8249  8256  8275  8277  8350  8366  8392  8473  8501\n",
      "  8509  8533  8570  8603  8680  8714  8743  8774  8807  8818  8824  8851\n",
      "  8874  8978  8986  8991  8998  9080  9106  9183  9247  9256  9274  9337\n",
      "  9338  9351  9367  9369  9394  9444  9500  9513  9523  9591  9663  9700\n",
      "  9777  9814  9825  9872  9889  9915 10026 10032 10050 10066 10084 10095\n",
      " 10100 10114 10143 10144 10200 10213 10244 10270 10417 10493 10520 10521\n",
      " 10562 10597 10600 10612 10659 10660 10669 10697 10702 10760 10808 10828\n",
      " 10864 10884 10905 10908 10911 10939 10968 10978 10982 11014 11023 11054\n",
      " 11059 11062 11064 11091 11103 11167 11178 11183 11207 11216 11297 11320\n",
      " 11348 11377 11429 11471 11507 11548 11557 11585 11610 11699 11752 11762\n",
      " 11782 11796 11841 11884 11891 11922 11961 11989 12088 12120 12153 12160\n",
      " 12161 12264 12279 12293 12300 12370 12441 12447 12472 12490 12554 12604\n",
      " 12668 12745 12809 12840 12856 12953 12959 12986 12987 13017 13061 13097\n",
      " 13100 13104 13125 13139 13222 13307 13320 13358 13397 13422 13439 13501\n",
      " 13504 13558 13607 13686 13715 13724 13732 13776 13782 13815 13833 13959\n",
      " 13975]\n"
     ]
    }
   ],
   "source": [
    "#Find true positive & false negatives \n",
    "import numpy as np\n",
    "\n",
    "y_pred = sgd_clf.predict(X_test)\n",
    "\n",
    "\n",
    "#Calcuating true positives & print them\n",
    "y_pred_positive = np.where(y_pred == True)\n",
    "y_test_positive = np.where(y_test == '5')\n",
    "y_true_positive = y_pred_positive and y_test_positive \n",
    "y_true_positive = y_true_positive[0] # The first element of this array contains the indices with true positives\n",
    "print(y_true_positive) \n",
    "\n",
    "#Calcuating fales negatives & print them\n",
    "y_pred_negative = np.where(y_pred == False)\n",
    "y_test_negative = np.where(y_test != '5')\n",
    "y_false_negative = np.setdiff1d(y_pred_negative, y_test_negative)\n",
    "\n",
    "print(y_false_negative) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFzklEQVR4nO3cz4tNfxzH8Ttfl0SkSTE1MhZ21CwtlJ9lYyPJgo0Utv4CVvwDKMXSjyKysGGh+AcQZSkLUZhsjKHc71rmvI+5d2a8ZubxWM6rc+8pPTvl9LlDvV6vA+T571/fADA9cUIocUIocUIocUKobsvuv3Jh7g1N90dPTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgjV/dc3QJapqanG7fXr1+W1w8PD5T42NtbPLf2VN2/elPv169cH+vxdu3Y1bgcPHhzos5t4ckIocUIocUIocUIocUIocUIocUIo7zkXmcnJyXJ/+PBhud+8ebNxu3//fnnt+Ph4uR86dKjcP3z40Lg9efKkvPbTp08D7W2WL1/euHnPCUuMOCGUOCGUOCGUOCGUOCGUOCHUUK/Xq/ZyZPZ9//693E+cOFHuz58/L/e2c48L1bp168q9261f6Z87d67cjx8/3vd3/4Wh6f7oyQmhxAmhxAmhxAmhxAmhxAmhxAmhnOcMc/bs2XK/ffv2nH7/ypUr+752z5495T4yMtL3Z7edBd2xY0e5T0xMlPvWrVtnfE9zzZMTQokTQokTQokTQokTQokTQokTQnnPGWbFihVz+vmbN28u95cvXzZua9eune3bmTfr16//17cwY56cEEqcEEqcEEqcEEqcEEqcEMqrlDDLli2b088/depUuS/k1yWLjScnhBInhBInhBInhBInhBInhBInhPKecw78+PGj3G/cuNG4Xb58eaDvPnr0aLmfPn16oM9n/nhyQihxQihxQihxQihxQihxQihxQijvOfvw+fPncj958mS5P3jwYDZv5zd79+4t9/fv35f7z58/G7eNGzf2dU/0x5MTQokTQokTQokTQokTQokTQokTQg31er1qL8el6syZM+V+9erVebqT2Tc2Nta4PXv2rLx2dHR0lu9myRia7o+enBBKnBBKnBBKnBBKnBBKnBBKnBDKec4+tJ3nHMSaNWvKvdut/8mOHDlS7rdu3Sr3t2/fNm7Xrl0rrz1//ny5MzOenBBKnBBKnBBKnBBKnBBKnBDKkbE+fPv2rdzbjlZVxsfHy33Dhg3l/uvXr3LfsmVLub97965xu3v3bnnt4cOHy51GjozBQiJOCCVOCCVOCCVOCCVOCCVOCOXIWB9WrVpV7gcOHJinO/nTnTt3yr16j9lmamqq72uZOU9OCCVOCCVOCCVOCCVOCCVOCCVOCLVo33O+evWqcbt06VJ5bdvPU7b9BOTq1avLvfLx48dyf/ToUblfvHix7+/udDqdbdu2NW779u0b6LOZGU9OCCVOCCVOCCVOCCVOCCVOCCVOCLVof7e2OlPZ9q6wzfDwcLlX7wo7nU5nYmKicWs7b/n169dyb7N9+/Zyv3LlSuO2c+fOgb6bRn63FhYScUIocUIocUIocUIocUKoRXtkbPfu3Y3b48ePy2tbXi91vnz5Uu5Pnz4t90GMjIyU+/79+8v9woUL5T46Ojrje2JueHJCKHFCKHFCKHFCKHFCKHFCKHFCqEV7ZKzy4sWLcr937165T05Ozubt/GbTpk3lfuzYsXJvO85GJEfGYCERJ4QSJ4QSJ4QSJ4QSJ4QSJ4Raku85IYz3nLCQiBNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCdVv2oXm5C+APnpwQSpwQSpwQSpwQSpwQSpwQ6n8JW8xzx771swAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We can now plot misclassified numbers\n",
    "#True positive number\n",
    "MNIST_PlotDigit(X_test[y_true_positive[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#False negative number\n",
    "MNIST_PlotDigit(X_test[y_false_negative[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qc Implement a dummy binary classifier\n",
    "\n",
    "Now we will try to create a Scikit-learn compatible estimator implemented via a python class. Follow the code found in [HOML], p.90, but name you estimator `DummyClassifier` instead of `Never5Classifyer`.\n",
    "\n",
    "Here our Python class knowledge comes into play. The estimator class hierarchy looks like\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/F20_itmal/L02/Figs/class_base_estimator.png\" style=\"width:500px\">\n",
    "\n",
    "All Scikit-learn classifiers inherit from `BaseEstimator` (and possibly also `ClassifierMixin`), and they must have a `fit-predict` function pair (strangely not in the base class!) and you can actually find the `sklearn.base.BaseEstimator` and `sklearn.base.ClassifierMixin` python source code somewhere in you anaconda install dir, if you should have the nerves to go to such interesting details.\n",
    "\n",
    "But surprisingly you may just want to implement a class that contains the `fit-predict` functions, ___without inheriting___ from the `BaseEstimator`, things still work due to the pythonic 'duck-typing': you just need to have the class implement the needed interfaces, obviously `fit()` and `predict()` but also the more obscure `get_params()` etc....then the class 'looks like' a `BaseEstimator`...and if it looks like an estimator, it _is_ an estimator (aka. duck typing).\n",
    "\n",
    "Templates in C++ also allow the language to use compile-time duck typing!\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Duck_typing\n",
    "\n",
    "Call the fit-predict on a newly instantiated `DummyClassifier` object, and find a way to extract the accuracy `score` from the test data. You may implement an accuracy function yourself or just use the `sklearn.metrics.accuracy_score` function. \n",
    "\n",
    "Finally, compare the accuracy score from your `DummyClassifier` with the scores found in [HOML] \"Measuring Accuracy Using Cross-Validation\", p.89. Are they comparable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class DummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "    def get_params():\n",
    "        pass\n",
    "\n",
    "dummy_clf = DummyClassifier()\n",
    "dummy_clf.fit(X, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True ... False False False]\n",
      "0.907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test_5,y_pred)\n",
    "\n",
    "print(y_test_5)\n",
    "\n",
    "print(score)\n",
    "# The accuracy is very similar because we are always guessing that a number is never a 5, \n",
    "# therefore about 90% of the time we are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qd Conclusion\n",
    "\n",
    "Now, conclude on all the exercise above. \n",
    "\n",
    "Write a short textual conclusion (max. 10- to 20-lines) that extract the _essence_ of the exercises: why did you think it was important to look at these particular ML concepts, and what was our overall learning outcome of the exercises (in broad terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We learn how to fetch a dataset using scikitlearn. We use this MNIST dataset to learn how to do a binary classification\n",
    "# with a stochastic descent gradient model. We then learn how to split a dataset in python into a training & test set, which \n",
    "# can use to train our model. \n",
    "# After training our model we can find various parameters to judge our model, and we find that even though we may have a lot\n",
    "# of true positive (Correct classification of the number 5) it does not necessarily mean our model is good. We need to hold \n",
    "# compare the amount of true positive to true negative, false positive and negative to get an accurate idea of whether our \n",
    "# model is useful for classifying our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}