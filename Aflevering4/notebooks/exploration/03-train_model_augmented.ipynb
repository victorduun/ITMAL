{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, random, pickle, json, itertools\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "from IPython.display import SVG\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Add, Input, Conv2D, Dropout, Activation, BatchNormalization, MaxPooling2D, ZeroPadding2D, AveragePooling2D, Flatten, Dense)\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, Callback\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functions loaded\n"
     ]
    }
   ],
   "source": [
    "def show_final_history(history):\n",
    "\n",
    "    plt.style.use(\"ggplot\")\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[1].set_title('Accuracy')\n",
    "    ax[0].plot(history.history['loss'],label='Train Loss')\n",
    "    ax[0].plot(history.history['val_loss'],label='Validation Loss')\n",
    "    ax[1].plot(history.history['acc'],label='Train Accuracy')\n",
    "    ax[1].plot(history.history['val_acc'],label='Validation Accuracy')\n",
    "\n",
    "    ax[0].legend(loc='upper right')\n",
    "    ax[1].legend(loc='lower right')\n",
    "    plt.show();\n",
    "    pass\n",
    "\n",
    "def conv_block(X, k, filters, stage, block, s=2):\n",
    "    conv_base_name = 'conv_' + str(stage) + block + '_branch'\n",
    "    bn_base_name = 'bn_' + str(stage) + block + \"_branch\"\n",
    "\n",
    "    F1 = filters\n",
    "\n",
    "    X = Conv2D(filters=F1, kernel_size=(k, k), strides=(s, s),\n",
    "               padding='same', name=conv_base_name + '2a')(X)\n",
    "    X = BatchNormalization(name=bn_base_name + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X\n",
    "    pass\n",
    "\n",
    "def augment_add(images, seq, labels):\n",
    "    augmented_images, augmented_labels = [],[]\n",
    "    for idx,img in tqdm(enumerate(images)):\n",
    "\n",
    "        if labels[idx] == 1:\n",
    "            image_aug_1 = seq.augment_image(image=img)\n",
    "            image_aug_2 = seq.augment_image(image=img)\n",
    "            augmented_images.append(image_aug_1)\n",
    "            augmented_images.append(image_aug_2)\n",
    "            augmented_labels.append(labels[idx])\n",
    "            augmented_labels.append(labels[idx])\n",
    "        pass\n",
    "\n",
    "    augmented_images = np.array(augmented_images, dtype=np.float32)\n",
    "    augmented_labels = np.array(augmented_labels, dtype=np.float32)\n",
    "\n",
    "    return (augmented_images, augmented_labels)\n",
    "    pass\n",
    "\n",
    "\n",
    "def basic_model(input_shape,classes):\n",
    "\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    X = ZeroPadding2D((5,5))(X_input)\n",
    "\n",
    "    X = Conv2D(16,(3,3),strides=(2,2),name='conv1',padding=\"same\")(X)\n",
    "    X = BatchNormalization(name='bn_conv1')(X)\n",
    "\n",
    "    # stage 2\n",
    "    X = conv_block(X,3,32,2,block='A',s=1)\n",
    "    X = MaxPooling2D((2,2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "\n",
    "#     Stage 3\n",
    "    X = conv_block(X,5,32,3,block='A',s=2)\n",
    "    X = MaxPooling2D((2,2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "\n",
    "#     Stage 4\n",
    "    X = conv_block(X,3,64,4,block='A',s=1)\n",
    "    X = MaxPooling2D((2,2))(X)\n",
    "    X = Dropout(0.25)(X)\n",
    "\n",
    "#   Output Layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(64)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    X = Dense(128)(X)\n",
    "    X = Activation(\"relu\")(X)\n",
    "\n",
    "    X = Dense(classes,activation=\"softmax\",name=\"fc\"+str(classes))(X)\n",
    "\n",
    "    model = Model(inputs=X_input,outputs=X,name='Feature_Extraction_and_FC')\n",
    "\n",
    "    return model\n",
    "    pass\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading ship data\")\n",
    "    ships_path = os.path.join('../../data/raw/','shipsnet.json')\n",
    "    with open(ships_path) as file:\n",
    "        dataset = json.load(file)\n",
    "\n",
    "    labels = np.array(dataset[\"labels\"]).astype(\"float32\")\n",
    "\n",
    "    img_length = 80\n",
    "    images = np.array(dataset[\"data\"]).astype(\"uint8\")\n",
    "    images = images.reshape(-1, 3, img_length, img_length).transpose([0, 2, 3, 1])\n",
    "    images = [cv2.cvtColor(img,cv2.COLOR_BGR2RGB) for img in images]\n",
    "    images = [cv2.resize(img, (48,48)) for img in images]\n",
    "    images = np.array(images,dtype=np.float32)/255.0\n",
    "    print(\"Data loaded\")\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "print(\"functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load data\n",
    "Loads the dataset and augments it such that the distribution between ship and noship classes is the same. Can choose between different types of augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ship data\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "#\"none\",\"rotate\", \"lighting\", \"flip\", \"mix\", \"class_weights\"\n",
    "AUGMENTATION_TYPE = \"class_weights\"\n",
    "\n",
    "(images, labels) = load_data()\n",
    "images.shape, labels.shape\n",
    "\n",
    "\n",
    "\n",
    "if AUGMENTATION_TYPE == \"rotate\":\n",
    "    seq = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        rotate=(-25,25),\n",
    "    )\n",
    "], random_order=True)\n",
    "if AUGMENTATION_TYPE == \"flip\":\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "], random_order=True)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"lighting\":\n",
    "    seq = iaa.Sequential([\n",
    "    iaa.LinearContrast((0.75,1.5)),\n",
    "], random_order=True)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"mix\":\n",
    "    seq = iaa.Sequential([\n",
    "    iaa.LinearContrast((0.75,1.5)),\n",
    "    iaa.Multiply((0.8,1.2), per_channel=True),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Affine(\n",
    "        rotate=(-25,25),\n",
    "    )\n",
    "], random_order=True)\n",
    "\n",
    "if AUGMENTATION_TYPE != \"none\" and AUGMENTATION_TYPE != \"class_weights\":\n",
    "    (aug_images, aug_labels) = augment_add(images, seq, labels)\n",
    "    images = np.concatenate([images, aug_images])\n",
    "    labels = np.concatenate([labels, aug_labels])\n",
    "    for i in range(5000,5004):\n",
    "        plt.imshow(images[i])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "labels = to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test, train split  + shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3200, 48, 48, 3), (800, 48, 48, 3))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(images)\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "\n",
    "total_count = len(images)\n",
    "total_count\n",
    "\n",
    "train = int(0.8*total_count)\n",
    "test = int(0.2*total_count)\n",
    "\n",
    "train_images, train_labels = images[:train], labels[:train]\n",
    "test_images, test_labels = images[-test:], labels[-test:]\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Image data generator\n",
    "Imagge data generator for creating test/validation splits. Also allows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=30\n",
    "if AUGMENTATION_TYPE == \"none\":\n",
    "    idg = ImageDataGenerator(validation_split=0.2)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"flip\":\n",
    "    idg = ImageDataGenerator(\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"rotate\":\n",
    "    idg = ImageDataGenerator(\n",
    "        rotation_range=30,\n",
    "        validation_split=0.2)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"lighting\":\n",
    "    idg = ImageDataGenerator(\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        validation_split=0.2)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"mix\":\n",
    "    idg = ImageDataGenerator(\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        rotation_range=30,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n",
    "\n",
    "idg.fit(train_images)\n",
    "\n",
    "if AUGMENTATION_TYPE == \"class_weights\":\n",
    "    classTotals = train_labels.sum(axis=0)\n",
    "    classWeight = {}\n",
    "\n",
    "    for i in range(0,len(classTotals)):\n",
    "        classWeight[i] = classTotals.max()/classTotals[i]\n",
    "        pass\n",
    "\n",
    "    classWeight\n",
    "\n",
    "train_generator = idg.flow(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    seed = 42,\n",
    "    shuffle=True,\n",
    "    subset=\"training\"\n",
    "    )\n",
    "\n",
    "val_generator = idg.flow(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    batch_size=batch_size,\n",
    "    seed = 42,\n",
    "    shuffle=True,\n",
    "    subset=\"validation\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Feature_Extraction_and_FC\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 58, 58, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 29, 29, 16)        448       \n",
      "_________________________________________________________________\n",
      "bn_conv1 (BatchNormalization (None, 29, 29, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv_2A_branch2a (Conv2D)    (None, 29, 29, 32)        4640      \n",
      "_________________________________________________________________\n",
      "bn_2A_branch2a (BatchNormali (None, 29, 29, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3A_branch2a (Conv2D)    (None, 7, 7, 32)          25632     \n",
      "_________________________________________________________________\n",
      "bn_3A_branch2a (BatchNormali (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv_4A_branch2a (Conv2D)    (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "bn_4A_branch2a (BatchNormali (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 62,530\n",
      "Trainable params: 62,242\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = basic_model(input_shape=(48,48,3),classes=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-4)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_weights_aug.h5\",monitor='val_acc',verbose=1,save_best_only=True,mode='max')\n",
    "logs = TensorBoard(\"logs\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 2/85 [..............................] - ETA: 1:07 - loss: 1.3342 - acc: 0.5667WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1620s vs `on_train_batch_end` time: 1.4600s). Check your callbacks.\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1382 - acc: 0.5822\n",
      "Epoch 00001: val_acc improved from -inf to 0.79206, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 9s 104ms/step - loss: 1.1382 - acc: 0.5822 - val_loss: 0.4293 - val_acc: 0.7921\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9080 - acc: 0.6605\n",
      "Epoch 00002: val_acc did not improve from 0.79206\n",
      "85/85 [==============================] - 7s 80ms/step - loss: 0.9080 - acc: 0.6605 - val_loss: 0.4319 - val_acc: 0.7683\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8300 - acc: 0.6909\n",
      "Epoch 00003: val_acc improved from 0.79206 to 0.79524, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 9s 101ms/step - loss: 0.8300 - acc: 0.6909 - val_loss: 0.4033 - val_acc: 0.7952\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7137 - acc: 0.7557\n",
      "Epoch 00004: val_acc did not improve from 0.79524\n",
      "85/85 [==============================] - 8s 91ms/step - loss: 0.7137 - acc: 0.7557 - val_loss: 0.4005 - val_acc: 0.7873\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6454 - acc: 0.7964\n",
      "Epoch 00005: val_acc improved from 0.79524 to 0.82540, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 8s 100ms/step - loss: 0.6454 - acc: 0.7964 - val_loss: 0.3554 - val_acc: 0.8254\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5684 - acc: 0.8174\n",
      "Epoch 00006: val_acc improved from 0.82540 to 0.84603, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 8s 91ms/step - loss: 0.5684 - acc: 0.8174 - val_loss: 0.3185 - val_acc: 0.8460\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5338 - acc: 0.8379\n",
      "Epoch 00007: val_acc improved from 0.84603 to 0.89206, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 8s 96ms/step - loss: 0.5338 - acc: 0.8379 - val_loss: 0.2448 - val_acc: 0.8921\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4902 - acc: 0.8545\n",
      "Epoch 00008: val_acc improved from 0.89206 to 0.91270, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 7s 88ms/step - loss: 0.4902 - acc: 0.8545 - val_loss: 0.2105 - val_acc: 0.9127\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4345 - acc: 0.8715- ETA: 0s - loss: 0.4395 - acc: \n",
      "Epoch 00009: val_acc improved from 0.91270 to 0.92381, saving model to model_weights_aug.h5\n",
      "85/85 [==============================] - 8s 93ms/step - loss: 0.4345 - acc: 0.8715 - val_loss: 0.1934 - val_acc: 0.9238\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4306 - acc: 0.8763\n",
      "Epoch 00010: val_acc did not improve from 0.92381\n",
      "85/85 [==============================] - 8s 93ms/step - loss: 0.4306 - acc: 0.8763 - val_loss: 0.1953 - val_acc: 0.9159\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3990 - acc: 0.8964- ETA: 1s - loss: 0.3988 \n",
      "Epoch 00011: val_acc did not improve from 0.92381\n",
      "85/85 [==============================] - 8s 90ms/step - loss: 0.3990 - acc: 0.8964 - val_loss: 0.2167 - val_acc: 0.9159\n",
      "Epoch 12/50\n",
      " 1/85 [..............................] - ETA: 0s - loss: 0.3268 - acc: 0.9333"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "if AUGMENTATION_TYPE != \"class_weights\":\n",
    "    history = model.fit(train_generator,\n",
    "                                  steps_per_epoch=train_generator.n//batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=val_generator.n//batch_size,\n",
    "                                  callbacks=[checkpoint, logs],\n",
    "                                  verbose=1)\n",
    "\n",
    "else:\n",
    "    history = model.fit(train_generator,\n",
    "                                  steps_per_epoch=train_generator.n//batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=val_generator.n//batch_size,\n",
    "                                  callbacks=[checkpoint, logs],\n",
    "                                  verbose=1,\n",
    "                                  class_weight=classWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_final_history(history)\n",
    "\n",
    "score, acc = model.evaluate(test_images, test_labels,)\n",
    "print(f\"Final test accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"ship-model-aug-{}-{:.3f}-acc.h5\".format(AUGMENTATION_TYPE, acc)\n",
    "model.save(model_name)\n",
    "print(f\"saved {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}